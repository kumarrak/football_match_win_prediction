---
title: "Football - Match Win Prediction"
author: "Naveen Kumar Kalluri | Ashok Kumar Rayapati | Varun Sai Rachulapally"
date: "4/27/2022"
output: html_document
---

### About API:

We collected data from "football-data.org" API, where we are using data of 21353 records related to matches which are obtained from 157 competitions.

API source: https://www.football-data.org/documentation/quickstart

### Business Contex & Problem Description:

- To be able to predict the future winner is always exciting. We will try to predict the probability of a team    winning the match based on their previous performances. 

- By this, we want to address the problems faced by investors/organizations that are investing huge sums of money in the teams.


### Link to download data collected from API.

https://github.com/kumarrak/football

```{r warning=FALSE}
rm(list = ls())
library(tidyverse)
library(caret) 
library(httr)
library(glue)
library(magrittr)
library(purrr)
library(repurrrsive)
library(kableExtra)
library(data.table)
library(h2o)
library(e1071)
library(skimr)
library(recipes)
library(stringr)
library(ggplot2)
library(ggthemes)
```

### Establishing a connection with API
```{r warning=FALSE}
token = "ff9d3d9ab03f431aaf64ea00464e31a0"
football_api = GET("https://api.football-data.org//v2/competitions",
                   add_headers("X-Auth-Token"= token)
)

# connection
conn = content(football_api)
competitions = conn$competitions

```
### Data Description:

We collected 21353 records of data from 157 competitions using API.

Data Consists of 10 predictive variables they are:

halfTime_score_Home, halfTime_score_Away, fullTime_score_Home, fullTime_score_Away, homeTeam, awayTeam ,Odds.homeWin, Odds.draw, Odds.awayWin and winner.

Winner is the y variable to be predicted.



### All competitons data from API
```{r warning=FALSE}

#Storing all competition id and their names in df
ids = map_int(competitions, ~.$id)
names = map_chr(competitions, ~.$name)

all_competitions = data.frame(id = ids, name = names)

#display all competitions
head(all_competitions, n=10) %>% kbl() %>% kable_minimal()

#Selecting required competitions by their id's from the API

SelctCompetitions = c(all_competitions[1:157,])
# All selected competitions from above

selected_comps = SelctCompetitions


#display all available compts
#selected_comps

#Retrieving match data from the API
matches_data = list()


for(id in selected_comps$id){
  url = glue("http://api.football-data.org/v2/competitions/{id}/matches?dateFrom=2020-02-01&dateTo=2022-04-01")
  matches_comp = GET(url, add_headers("X-Auth-Token"= token))
  matches_data = append(matches_data, content(matches_comp))
}

all_matches = matches_data[names(matches_data) == "matches"]
#summary(all_matches)
```

### Collecting matches data from above competitions
#### Converting list of matches to a df.
```{r warning=FALSE}

matches_df = data.frame()
for(x in 1:10){
  tbl <- as_tibble(all_matches)
  matches_df <- bind_rows(matches_df, unnest_wider(tbl,matches))
}

```

### Selecting the required columns
```{r warning=FALSE}
matches_df <- subset (matches_df, select = -c(1,7,13))
```


```{r warning=FALSE}
head(matches_df, n=10) %>% kbl() %>% kable_minimal()
```

### Data cleaning

```{r warning=FALSE}
matches_df  <- matches_df %>%
  mutate(df = map(odds, ~ .x %>% 
                    map_df(magrittr::extract,)))

```


```{r warning=FALSE}
head(matches_df, n=10) %>% kbl() %>% kable_minimal()
```


```{r warning=FALSE}
matches_df  <- matches_df  %>%
  select(-odds) %>% 
  unnest(df)
```

### Renaming the columns
```{r warning=FALSE}

matches_df <- matches_df %>% 
  dplyr::rename(
    Odds.homeWin = homeWin,
    Odds.draw = draw,
    Odds.awayWin = awayWin
  )

```

### Converting list data to a column (awayTeam column)

```{r warning=FALSE}

matches_df  <- matches_df %>%
  mutate(df = map(awayTeam, ~ .x %>% 
                    map_df(magrittr::extract, 
                    )))
matches_df  <- matches_df  %>%
  select(-awayTeam) %>%
  unnest(df)

matches_df <- subset (matches_df, select = -c(id))

matches_df <- matches_df %>% 
  dplyr::rename(
    awayTeam = name
  )

```

### Converting list data to a column (homeTeam column)

```{r warning=FALSE}
matches_df  <- matches_df %>%
  mutate(df = map(homeTeam, ~ .x %>% 
                    map_df(magrittr::extract, 
                    )))

matches_df  <- matches_df  %>%
  select(-homeTeam) %>%
  unnest(df)

matches_df <- subset (matches_df, select = -c(id))
matches_df <- matches_df %>% 
  dplyr::rename(
    homeTeam = name
  )
#head(matches_df, n=10) %>% kbl() %>% kable_minimal()
```


### full time and half time goals of the homeTeam and awayTeam


```{r warning=FALSE}
scores = matches_df$score
winner_vector = map_chr(scores,"winner", .default = NA)

fullTimeScores = map(scores,"fullTime")
fTHome = map_int(fullTimeScores,"homeTeam", .default = NA)
fTAway = map_int(fullTimeScores,"awayTeam", .default = NA)

halfTimeScores = map(scores,"halfTime")
hTHome = map_int(halfTimeScores,"homeTeam", .default = NA)
hTAway = map_int(fullTimeScores,"awayTeam", .default = NA)


matches_df$halfTime_score_Home = hTHome
matches_df$halfTime_score_Away = hTAway
matches_df$fullTime_score_Home = fTHome
matches_df$fullTime_score_Away = fTAway
matches_df$winner = winner_vector

head(matches_df, n=10) %>% kbl() %>% kable_minimal()
```


```{r warning=FALSE}
football_df <- subset (matches_df, select = -c(score))

football_df <- football_df[, c("Odds.homeWin","Odds.draw","Odds.awayWin","halfTime_score_Home", "halfTime_score_Away","fullTime_score_Home", "fullTime_score_Away", "homeTeam", "awayTeam","winner")]
```

### Writing the data obtained to CSV
```{r warning=FALSE}
head(football_df, n=10) %>% kbl() %>% kable_minimal()

write.csv(football_df, file="football_api_data.csv", row.names = FALSE)
```

### reading data files and combining

```{r warning=FALSE}

dff <- read.csv(file ="https://raw.githubusercontent.com/kumarrak/football/main/football_api_full.csv")

dff1 <- read.csv(file ="https://raw.githubusercontent.com/kumarrak/football/main/football_api_full1..csv")

dff2 <- read.csv(file ="https://raw.githubusercontent.com/kumarrak/football/main/football_api_full2.csv")

df_complete <- do.call('rbind', list(dff1, dff2, dff))
```

### Total No.of records before droping NA:

```{r warning=FALSE}
nrow(df_complete)
```

### Drop rows with NA values

```{r warning=FALSE}
colSums(is.na(df_complete))
df_complete <- drop_na(df_complete)
view(df_complete)
```

### Total No.of records after cleaning: 21260
```{r warning=FALSE}
nrow(df_complete)
```

### Converting character values to integer values in predictor column

```{r warning=FALSE}
#Assessing the winner based on the outcome of the match
#0 = Draw match, 1 = Home team Win, 2 = Away team Win
df_complete$winner <- ifelse(df_complete$winner == "DRAW",0,df_complete$winner)
df_complete$winner <- ifelse(df_complete$winner == "HOME_TEAM",1,df_complete$winner)
df_complete$winner <- ifelse(df_complete$winner == "AWAY_TEAM",2,df_complete$winner)
df_complete$winner <- as.factor(df_complete$winner)
```

### Final dataset

```{r warning=FALSE}
head(df_complete, n=10) %>% kbl() %>% kable_minimal()
```


### Data Exploration

### Plot 1
##### Count of Matche (Wins,draws) with respect to Home team and Away team

```{r warning=FALSE}
ggplot(df_complete, aes(x=winner, fill=winner )) + 
  geom_bar(colour="black")+
  geom_text( stat='count', aes(label=..count..), vjust= 2, position = position_dodge(.9) ) +
  theme_economist()+
  scale_fill_discrete(name = "Winner", labels = c("Draw", "Home Team", "Away Team"))

```

### Plot 2
##### Top Home Winners 

```{r warning=FALSE}
homewins =subset(df_complete, winner==1) %>% count(homeTeam )
homewins <- homewins[with(homewins,order(-n)),]
homewins <- homewins[1:10,]



ggplot(data = homewins, aes(y = reorder(homeTeam, n), x = n, fill = homeTeam)) +
  geom_bar(stat = "identity", position = 'dodge')+
  geom_text(aes(label = n), vjust = 1.5, colour = "black")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.6))+
  xlab("wins") +
  ylab("Team Name")+
  theme_gdocs()+
  labs(title = "Top Home Winners")+
  theme(legend.position="none")


```
### Plot 3
##### Top Away Winners 



```{r warning=FALSE}
awaywins =subset(df_complete, winner==2) %>% count(awayTeam )
awaywins <- awaywins[with(awaywins,order(-n)),]
awaywins <- awaywins[1:10,]

ggplot(data = awaywins, aes(y = reorder(awayTeam, n), x = n, fill = awayTeam)) +
  geom_bar(stat = "identity", position = 'dodge')+
  geom_text(aes(label = n), vjust = 1.5, colour = "black")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.6))+
  xlab("wins") +
  ylab("Team Name")+
  theme_gdocs()+
  labs(title = "Top Away Winners")+
  theme(legend.position="none")
```

### Plot 4
#### Top Three teams with respect to Home wins, Away wins and Draw

```{r warning=FALSE}
count_homewins_top3 <- homewins[1:3,]
count_homewins_top3 <- count_homewins_top3[, c('homeTeam')]
three_team_df <- df_complete[, c('homeTeam', 'winner')] %>% 
  filter(grepl('CA Mineiro|CR Flamengo|Fluminense FC', homeTeam))%>% 
  group_by(homeTeam)

ggplot(three_team_df, aes(homeTeam)) + 
  geom_bar(aes(fill = winner), position="dodge")+
  theme_gdocs()+
  theme(axis.text.x = element_text(angle = 0, vjust = 0.5))+
  geom_text( stat='count', aes(fill = winner, label=..count..), vjust= 2, position = position_dodge(.9) )+
  scale_fill_manual(values=c("#EC7063","#AF7AC5","#F5D6B1"))
```


### Split the dataset into train (80%) and test (20%).
##### Train Data
```{r warning=FALSE}
set.seed(200)
trainIndex <- createDataPartition(df_complete$winner,p = 0.8,list = FALSE)

traindata <- df_complete[trainIndex,]
nrow(traindata)
head(traindata, n=10) %>% kbl() %>% kable_minimal()
```

##### Test Data

```{r warning=FALSE}
testdata <- df_complete[-trainIndex,]
nrow(testdata)
head(testdata, n=10) %>% kbl() %>% kable_minimal()
```
### Model Building

#### Naive Bayes Model 
##### Fitting to training dataset

```{r warning=FALSE}
nvclassifier <- naiveBayes(winner ~ ., data = traindata)
#nvclassifier

# Predicting on test data'
y_pred <- predict(nvclassifier, newdata = testdata)

# Confusion Matrix
cm <- table(testdata$winner, y_pred)
#cm

# Model Evaluation
confusionMatrix(cm)
```

### Organize the data:
#### Training data & Testing data

```{r warning=FALSE}

x_train_tbl <- traindata %>% select(-winner)
y_train_tbl <- traindata %>% select(winner)
x_test_tbl <-testdata %>% select(-winner)
```

### Data inspection

```{r warning=FALSE}
x_train_tbl_skim = partition(skim(x_train_tbl))
names(x_train_tbl_skim)
```

### Data Wrangling

```{r warning=FALSE}

string_2_factor_names <- x_train_tbl_skim$character$skim_variable
string_2_factor_names


unique_numeric_values_tbl <- x_train_tbl %>%
  select(x_train_tbl_skim$numeric$skim_variable) %>%
  map_df(~ unique(.) %>% length()) %>%
  gather() %>%
  arrange(value) %>%
  mutate(key = as_factor(key))
unique_numeric_values_tbl

factor_limit <- 25
num_2_factor_names <- unique_numeric_values_tbl %>%
  filter(value < factor_limit) %>%
  arrange(desc(value)) %>%
  pull(key) %>% # pull out a single variable as a vector
  as.character()
num_2_factor_names
```

### Recipes for ML Data Transformation

```{r warning=FALSE}
rec_obj <- recipe(~ ., data = x_train_tbl) %>%
  step_string2factor(all_of(string_2_factor_names)) %>%
  step_num2factor(all_of(num_2_factor_names),
                  levels=str_c(0:1000),
                  transform = function(x) x + 1) %>%
  step_impute_mean(all_numeric()) %>% # missing values in numeric columns
  step_impute_mode(all_nominal()) %>% # missing values in factor columns
  prep(training = x_train_tbl)

rec_obj
```

### Start baking:

```{r warning=FALSE}
x_train_processed_tbl <- bake(rec_obj, x_train_tbl)
x_test_processed_tbl <- bake(rec_obj, x_test_tbl)
```

### Transforming the outcome variable (y):

```{r warning=FALSE}
rec_obj_for_y <- recipe(~ ., data = y_train_tbl) %>%
  prep(stringsAsFactors = FALSE)
y_train_processed_tbl <- bake(rec_obj_for_y, y_train_tbl)

```




### Deep Learning model using H2o 

```{r warning=FALSE}
h2o.init(nthreads = -1)
```



```{r warning=FALSE}
data_h2o <- as.h2o(
  bind_cols(y_train_processed_tbl, x_train_processed_tbl),
  destination_frame= "train.hex") 

new_data_h2o <- as.h2o(
  x_test_processed_tbl,
  destination_frame= "test.hex"
)

data_h2o_no_destination <- as.h2o(
  bind_cols(y_train_processed_tbl, x_train_processed_tbl)
)

h2o.ls()
```

### Splitting the training data into 3 subsets:
##### 70:15:15 split

```{r warning=FALSE}
splits <- h2o.splitFrame(data = data_h2o, seed = 555,
                         ratios = c(0.7, 0.15))
train_h2o <- splits[[1]] 
valid_h2o <- splits[[2]]
test_h2o <- splits[[3]]
```



### Deep Learning Model 1
```{r warning=FALSE}
y <- "winner" # column name for outcome
x <- colnames(select(df_complete,-c('winner','homeTeam','awayTeam','fullTime_score_Home','fullTime_score_Away')))

m1 <- h2o.deeplearning(
  model_id = "dl_model_first",
  x = x,
  y = y,
  training_frame = train_h2o,
  validation_frame = valid_h2o, 
  epochs = 1000
)

summary(m1)
```


### Deep Learning Model 2 
#### After tuning

```{r warning=FALSE}
m2 <- h2o.deeplearning(
  model_id="dl_model_tuned",
  x = x,
  y = y,
  training_frame = train_h2o,
  validation_frame = valid_h2o,
  overwrite_with_best_model = F, ## Return the final model after 100 epochs,
  ## even if not the best
  hidden = c(150,150,150), ## more hidden layers -> more complex interactions
  epochs = 50, 
  score_validation_samples = 10000, ## downsample validation set for faster scoring
  score_duty_cycle = 0.025, ## don't score more than 2.5% of the wall time
  adaptive_rate = F, ## manually tuned learning rate
  rate = 0.01,
  rate_annealing = 2e-6,
  momentum_start = 0.2, ## manually tuned momentum
  momentum_stable = 0.4,
  momentum_ramp = 1e7,
  l1 = 1e-5, ## add some L1/L2 regularization
  l2 = 1e-5,
  max_w2 = 10 ## helps stability for Rectifier
)

summary(m2)
```

### Hyper-parameter tuning with grid search

```{r warning=FALSE}
hyper_params <- list(
  hidden = list( c(150,150,150), c(60,60) ),
  input_dropout_ratio = c(0, 0.05),
  rate = c(0.01, 0.02),
  rate_annealing = c(1e-8, 1e-7, 1e-6)
)

grid <- h2o.grid(
  algorithm="deeplearning",
  grid_id="dl_grid",
  x = x,
  y = y,
  training_frame = train_h2o,
  validation_frame = valid_h2o,
  epochs = 50,
  stopping_metric = "misclassification",
  stopping_tolerance = 1e-2, 
  stopping_rounds = 2,
  score_validation_samples = 10000, ## downsample validation set for faster scoring
  score_duty_cycle = 0.025, ## don't score more than 2.5% of the wall time
  adaptive_rate = F, #manually tuned learning rate
  momentum_start = 0.5, #manually tuned momentum
  momentum_stable = 0.9,
  momentum_ramp = 1e7,
  l1 = 1e-5,
  l2 = 1e-5,
  activation = c("Rectifier"),
  max_w2 = 10, #can help improve stability for Rectifier
  hyper_params = hyper_params
)

grid <- h2o.getGrid("dl_grid", sort_by="logloss", decreasing=FALSE)
dl_grid_summary_table <- grid@summary_table
dl_grid_summary_table
```

### To find best model in the grid

```{r warning=FALSE}
dl_grid_best_model <- h2o.getModel(dl_grid_summary_table$model_ids[1])
summary(dl_grid_best_model)
```

### To find parameters used in the best model

```{r warning=FALSE}
dl_grid_best_model_params <- dl_grid_best_model@allparameters
dl_grid_best_model_params
```

### AutoML in h2o

```{r warning=FALSE}
automl_models_h2o <- h2o.automl(
  x = x,
  y = y,
  training_frame = train_h2o,
  validation_frame = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs = 200 
)

automl_leaderboard <- automl_models_h2o@leaderboard
automl_leaderboard

automl_leader <- automl_models_h2o@leader

performance_h2o <- h2o.performance(automl_leader, newdata = test_h2o)
performance_h2o %>%
  h2o.confusionMatrix()

```

### Shutdown the h2o:

```{r warning=FALSE}
h2o.shutdown(prompt = F)
```

### Summary:

After splitting the dataset into 80% of traing data and the rest as testing data.

We have applied Naive Bayes model to the test data and got an accuracy of 72%. 

Then we have fitted with train and validation data which is obtained from 80% of the original data, the accuracy of the model seems to fall below with test data compared to train and validation data as the epochs increase.
